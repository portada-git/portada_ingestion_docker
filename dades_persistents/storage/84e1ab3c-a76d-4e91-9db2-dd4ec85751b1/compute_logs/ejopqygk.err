2026-02-03 22:37:57 +0000 - dagster - DEBUG - ingestion - 84e1ab3c-a76d-4e91-9db2-dd4ec85751b1 - 13981 - LOGS_CAPTURED - Started capturing logs in process (pid: 13981).
2026-02-03 22:37:57 +0000 - dagster - DEBUG - ingestion - 84e1ab3c-a76d-4e91-9db2-dd4ec85751b1 - 13981 - ingested_entry_file - STEP_START - Started execution of step "ingested_entry_file".
Warning: Ignoring non-Spark config property: mapreduce.fileoutputcommitter.algorithm.version
Ivy Default Cache set to: /home/spark/.ivy2/cache
The jars for the packages stored in: /home/spark/.ivy2/jars
io.delta#delta-spark_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-464098cc-3158-4ca4-b1aa-e1963cefd220;1.0
	confs: [default]
	found io.delta#delta-spark_2.12;3.2.1 in central
	found io.delta#delta-storage;3.2.1 in central
	found org.antlr#antlr4-runtime;4.9.3 in central
:: resolution report :: resolve 83ms :: artifacts dl 4ms
	:: modules in use:
	io.delta#delta-spark_2.12;3.2.1 from central in [default]
	io.delta#delta-storage;3.2.1 from central in [default]
	org.antlr#antlr4-runtime;4.9.3 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-464098cc-3158-4ca4-b1aa-e1963cefd220
	confs: [default]
	0 artifacts copied, 3 already retrieved (0kB/4ms)
26/02/03 22:37:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Error reading file /app/ingestion/entry/jcanell4/results_boatdata.extractor.json: [Errno 2] No such file or directory: '/app/ingestion/entry/jcanell4/results_boatdata.extractor.json'
2026-02-03 22:37:59 +0000 - dagster - ERROR - ingestion - 84e1ab3c-a76d-4e91-9db2-dd4ec85751b1 - 13981 - ingested_entry_file - STEP_FAILURE - Execution of step "ingested_entry_file" failed.

dagster._core.errors.DagsterExecutionStepExecutionError: Error occurred while executing op "ingested_entry_file"::

FileNotFoundError: [Errno 2] No such file or directory: '/app/ingestion/entry/jcanell4/results_boatdata.extractor.json'

Stack Trace:
  File "/usr/lib/python3.12/site-packages/dagster/_core/execution/plan/utils.py", line 57, in op_execution_error_boundary
    yield
  File "/usr/lib/python3.12/site-packages/dagster/_utils/__init__.py", line 394, in iterate_with_context
    next_output = next(iterator)
                  ^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/site-packages/dagster/_core/execution/plan/compute_generator.py", line 135, in _coerce_op_compute_fn_to_iterator
    result = invoke_compute_fn(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/site-packages/dagster/_core/execution/plan/compute_generator.py", line 115, in invoke_compute_fn
    return fn(context, **args_to_pass) if context_arg_provided else fn(**args_to_pass)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/site-packages/dagster_portada_project/assets/boat_fact_ingestion_assets.py", line 17, in ingested_entry_file
    data, dest_path = layer.copy_ingested_raw_data("ship_entries", local_path=local_path, return_dest_path=True, user=user)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/site-packages/portada_data_layer/data_lake_metadata_manager.py", line 424, in wrapper
    return __is_data_transformer(func, "self", dataframe_key, description, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/site-packages/portada_data_layer/data_lake_metadata_manager.py", line 118, in __is_data_transformer
    resultat = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/site-packages/portada_data_layer/portada_ingestion.py", line 106, in copy_ingested_raw_data
    raise e
  File "/usr/lib/python3.12/site-packages/portada_data_layer/portada_ingestion.py", line 91, in copy_ingested_raw_data
    with open(local_path) as f:
         ^^^^^^^^^^^^^^^^

