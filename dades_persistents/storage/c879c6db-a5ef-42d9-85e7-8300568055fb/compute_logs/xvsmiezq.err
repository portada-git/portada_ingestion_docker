2026-02-03 16:45:27 +0000 - dagster - DEBUG - ingestion - c879c6db-a5ef-42d9-85e7-8300568055fb - 664 - LOGS_CAPTURED - Started capturing logs in process (pid: 664).
2026-02-03 16:45:27 +0000 - dagster - DEBUG - ingestion - c879c6db-a5ef-42d9-85e7-8300568055fb - 664 - raw_entries - STEP_START - Started execution of step "raw_entries".
2026-02-03 16:45:27 +0000 - dagster - DEBUG - ingestion - c879c6db-a5ef-42d9-85e7-8300568055fb - raw_entries - Loading file from: /opt/dagster/dagster_home/storage/ingested_entry_file using PickledObjectFilesystemIOManager...
2026-02-03 16:45:28 +0000 - dagster - DEBUG - ingestion - c879c6db-a5ef-42d9-85e7-8300568055fb - 664 - raw_entries - LOADED_INPUT - Loaded input "data" using input manager "io_manager", from output "result" of step "ingested_entry_file"
2026-02-03 16:45:28 +0000 - dagster - DEBUG - ingestion - c879c6db-a5ef-42d9-85e7-8300568055fb - 664 - raw_entries - STEP_INPUT - Got input "data" of type "Any". (Type check passed).
Warning: Ignoring non-Spark config property: mapreduce.fileoutputcommitter.algorithm.version
Ivy Default Cache set to: /home/spark/.ivy2/cache
The jars for the packages stored in: /home/spark/.ivy2/jars
io.delta#delta-spark_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-6f82cad9-864a-4847-85df-e415a034d51c;1.0
	confs: [default]
	found io.delta#delta-spark_2.12;3.2.1 in central
	found io.delta#delta-storage;3.2.1 in central
	found org.antlr#antlr4-runtime;4.9.3 in central
:: resolution report :: resolve 94ms :: artifacts dl 4ms
	:: modules in use:
	io.delta#delta-spark_2.12;3.2.1 from central in [default]
	io.delta#delta-storage;3.2.1 from central in [default]
	org.antlr#antlr4-runtime;4.9.3 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-6f82cad9-864a-4847-85df-e415a034d51c
	confs: [default]
	0 artifacts copied, 3 already retrieved (0kB/4ms)
26/02/03 16:45:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 4) / 4][Stage 0:=============================>                             (2 + 2) / 4]                                                                                26/02/03 16:45:36 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2026-02-03 16:46:04 +0000 - dagster - DEBUG - ingestion - c879c6db-a5ef-42d9-85e7-8300568055fb - 664 - raw_entries - STEP_OUTPUT - Yielded output "result" of type "Nothing". (Type check passed).
2026-02-03 16:46:04 +0000 - dagster - DEBUG - ingestion - c879c6db-a5ef-42d9-85e7-8300568055fb - 664 - raw_entries - ASSET_MATERIALIZATION - Materialized value raw_entries.
2026-02-03 16:46:04 +0000 - dagster - DEBUG - ingestion - c879c6db-a5ef-42d9-85e7-8300568055fb - 664 - raw_entries - STEP_SUCCESS - Finished execution of step "raw_entries" in 36.79s.
