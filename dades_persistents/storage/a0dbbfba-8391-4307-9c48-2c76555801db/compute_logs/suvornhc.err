2026-01-28 18:55:55 +0000 - dagster - DEBUG - ingestion - a0dbbfba-8391-4307-9c48-2c76555801db - 38868 - LOGS_CAPTURED - Started capturing logs in process (pid: 38868).
2026-01-28 18:55:55 +0000 - dagster - DEBUG - ingestion - a0dbbfba-8391-4307-9c48-2c76555801db - 38868 - raw_entries - STEP_START - Started execution of step "raw_entries".
2026-01-28 18:55:55 +0000 - dagster - DEBUG - ingestion - a0dbbfba-8391-4307-9c48-2c76555801db - raw_entries - Loading file from: /opt/dagster/dagster_home/storage/ingested_entry_file using PickledObjectFilesystemIOManager...
2026-01-28 18:55:55 +0000 - dagster - DEBUG - ingestion - a0dbbfba-8391-4307-9c48-2c76555801db - 38868 - raw_entries - LOADED_INPUT - Loaded input "data" using input manager "io_manager", from output "result" of step "ingested_entry_file"
2026-01-28 18:55:55 +0000 - dagster - DEBUG - ingestion - a0dbbfba-8391-4307-9c48-2c76555801db - 38868 - raw_entries - STEP_INPUT - Got input "data" of type "Any". (Type check passed).
Ivy Default Cache set to: /root/.ivy2/cache
The jars for the packages stored in: /root/.ivy2/jars
io.delta#delta-spark_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-61986e96-1f6b-49f0-8c05-20a49c021694;1.0
	confs: [default]
	found io.delta#delta-spark_2.12;3.2.1 in central
	found io.delta#delta-storage;3.2.1 in central
	found org.antlr#antlr4-runtime;4.9.3 in central
:: resolution report :: resolve 72ms :: artifacts dl 2ms
	:: modules in use:
	io.delta#delta-spark_2.12;3.2.1 from central in [default]
	io.delta#delta-storage;3.2.1 from central in [default]
	org.antlr#antlr4-runtime;4.9.3 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-61986e96-1f6b-49f0-8c05-20a49c021694
	confs: [default]
	0 artifacts copied, 3 already retrieved (0kB/2ms)
26/01/28 18:55:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                        (0 + 16) / 16][Stage 0:===>                                                     (1 + 15) / 16][Stage 0:=================================================>       (14 + 2) / 16][Stage 0:=========================================================(16 + 0) / 16]                                                                                ----------------------------------------
Exception occurred during processing of request from ('127.0.0.1', 56766)
ERROR:root:Exception while sending command.
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/socketserver.py", line 318, in _handle_request_noblock
    self.process_request(request, client_address)
  File "/usr/local/lib/python3.12/socketserver.py", line 349, in process_request
    self.finish_request(request, client_address)
  File "/usr/local/lib/python3.12/socketserver.py", line 362, in finish_request
    self.RequestHandlerClass(request, client_address, self)
  File "/usr/local/lib/python3.12/socketserver.py", line 766, in __init__
    self.handle()
  File "/usr/local/lib/python3.12/site-packages/pyspark/accumulators.py", line 295, in handle
    poll(accum_updates)
  File "/usr/local/lib/python3.12/site-packages/pyspark/accumulators.py", line 267, in poll
    if self.rfile in r and func():
                           ^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pyspark/accumulators.py", line 271, in accum_updates
    num_updates = read_int(self.rfile)
                  ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pyspark/serializers.py", line 596, in read_int
    raise EOFError
EOFError
----------------------------------------
2026-01-28 18:56:06 +0000 - dagster - ERROR - ingestion - a0dbbfba-8391-4307-9c48-2c76555801db - 38868 - raw_entries - STEP_FAILURE - Execution of step "raw_entries" failed.

dagster._core.errors.DagsterExecutionStepExecutionError: Error occurred while executing op "raw_entries"::

py4j.protocol.Py4JError: An error occurred while calling o73.save

Stack Trace:
  File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/utils.py", line 57, in op_execution_error_boundary
    yield
  File "/usr/local/lib/python3.12/site-packages/dagster/_utils/__init__.py", line 394, in iterate_with_context
    next_output = next(iterator)
                  ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/compute_generator.py", line 135, in _coerce_op_compute_fn_to_iterator
    result = invoke_compute_fn(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/dagster/_core/execution/plan/compute_generator.py", line 115, in invoke_compute_fn
    return fn(context, **args_to_pass) if context_arg_provided else fn(**args_to_pass)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/dagster_portada_project/assets/boat_fact_ingestion_assets.py", line 29, in raw_entries
    layer.save_raw_data(data=data, user=user)
  File "/usr/local/lib/python3.12/site-packages/portada_data_layer/portada_ingestion.py", line 525, in save_raw_data
    return super().save_raw_data(self.__container_path, user=user, data=data, source_path=source_path, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/portada_data_layer/data_lake_metadata_manager.py", line 424, in wrapper
    return __is_data_transformer(func, "self", dataframe_key, description, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/portada_data_layer/data_lake_metadata_manager.py", line 118, in __is_data_transformer
    resultat = func(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/portada_data_layer/portada_ingestion.py", line 216, in save_raw_data
    start_counter = self.get_sequence_value("entry_ships", BoatFactDataModel(data_json_array[0])["publication_name"].lower(), increment=len(data_json_array))
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/portada_data_layer/delta_data_layer.py", line 624, in get_sequence_value
    df.write.format("delta").save(path)
  File "/usr/local/lib/python3.12/site-packages/pyspark/sql/readwriter.py", line 1463, in save
    self._jwrite.save(path)
  File "/usr/local/lib/python3.12/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(

